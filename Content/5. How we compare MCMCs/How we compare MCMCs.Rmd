---
title: "How we compare MCMCs"
author: "Perry de Valpine"
date: "September 2019"
output:
  slidy_presentation: default
  beamer_presentation: default
---
<style>
slides > slide {
  overflow-x: auto !important;
  overflow-y: auto !important;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = FALSE)
library(nimble)
library(compareMCMCs)
library(coda)
recalculate <- FALSE
```

Mixing and computation time are both important
=====

Mixing refers to how well the MCMC samples around the posterior ("target distribution").

Computation time refers to the time taken by the MCMC.

Efficiency = Effective sample size / computation time.

Pace = 1/Efficiency

**Do not get excited about an MCMC just because it runs quickly.**

Sometimes fancy samplers are too slow to be worthwhile.

We ignore setup time because it is less interesting.  We don't thin because it confuses comparisons.

Let's look at the occupancy example.

Package `compareMCMCs`
=====

This used to be part of `nimble`.

It's nearly completely re-written as a separate package.  It's [here](https://github.com/nimble-dev/compareMCMCs).

There is a User Manual set up to be a package vignette [here](https://htmlpreview.github.io/?https://github.com/nimble-dev/compareMCMCs/blob/master/UserManual/compareMCMCs.html).

It's not yet on CRAN, so please install from GitHub:

```{r eval = FALSE}
library(devtools)
install_github("nimble-dev/compareMCMCs", subdir = "compareMCMCs")
```

Occupancy example
=====
This slide sets up the occupancy example.

(This code is modified from AHM.  It is here for completeness.)
```{r}
DO_PLOT <- TRUE
if(!exists("DO_PLOT"))
  DO_PLOT <- FALSE
print("do plot")
print(DO_PLOT)
# Choose sample sizes and prepare obs. data array y
set.seed(1)                   # So we all get same data set
M <- 100                      # Number of sites
J <- 3                        # Number of presence/absence measurements
y <- matrix(NA, nrow = M, ncol = J) # to contain the obs. data

# Create a covariate called vegHt
vegHt <- sort(runif(M, -1, 1)) # sort for graphical convenience

# Choose parameter values for occupancy model and compute occupancy
beta0 <- 0                    # Logit-scale intercept
beta1 <- 3                    # Logit-scale slope for vegHt
psi <- plogis(beta0 + beta1 * vegHt) # Occupancy probability
# plot(vegHt, psi, ylim = c(0,1), type = "l", lwd = 3) # Plot psi relationship

# Now visit each site and observe presence/absence perfectly
z <- rbinom(M, 1, psi)        # True presence/absence

# Look at data so far
table(z)

# Plot the true system state
if(DO_PLOT) {
  par(mfrow = c(1, 3), mar = c(5,5,2,2), cex.axis = 1.5, cex.lab = 1.5)
  plot(vegHt, z, xlab="Vegetation height", ylab="True presence/absence (z)", frame = F, cex = 1.5)
  plot(function(x) plogis(beta0 + beta1*x), -1, 1, add=T, lwd=3, col = "red")
}

# Create a covariate called wind
wind <- array(runif(M * J, -1, 1), dim = c(M, J))

# Choose parameter values for measurement error model and compute detectability
alpha0 <- -2                        # Logit-scale intercept
alpha1 <- -3                        # Logit-scale slope for wind
p <- plogis(alpha0 + alpha1 * wind) # Detection probability
# plot(p ~ wind, ylim = c(0,1))     # Look at relationship

# Take J = 3 presence/absence measurements at each site
for(j in 1:J) {
  y[,j] <- rbinom(M, z, p[,j])
}
sum(apply(y, 1, max))               # Number of sites with observed presences

# Plot observed data and true effect of wind on detection probability
if(DO_PLOT) {
  plot(wind, y, xlab="Wind", ylab="Observed det./nondetection data (y)", frame = F, cex = 1.5)
  plot(function(x) plogis(alpha0 + alpha1*x), -1, 1, add=T, lwd=3, col = "red")
}
# Look at the data: occupancy, true presence/absence (z), and measurements (y)
cbind(psi=round(psi,2), z=z, y1=y[,1], y2=y[,2], y3=y[,3])

# Create factors
time <- matrix(rep(as.character(1:J), M), ncol = J, byrow = TRUE)
hab <- c(rep("A", 33), rep("B", 33), rep("C", 34))  # Must have M = 100

# Bundle and summarize data set
str( occupancy_data <- list(y = y, 
                            vegHt = vegHt,
                            wind = wind,
                            M = nrow(y),
                            J = ncol(y),
                            XvegHt = seq(-1, 1, length.out=100),
                            Xwind = seq(-1, 1, length.out=100)) )

# Initial values: must give for same quantities as priors given !
zst <- apply(y, 1, max)        # Avoid data/model/inits conflict
occupancy_inits <- function(){
  list(z = zst, 
       mean.p = runif(1), 
       alpha1 = runif(1), 
       mean.psi = runif(1), 
       beta1 = runif(1))
}
```

```{r}
Section10p4_code <- nimbleCode({
  # Priors
  mean.p ~ dunif(0, 1)         # Detection intercept on prob. scale
  alpha0 <- logit(mean.p)      # Detection intercept
  alpha1 ~ dunif(-20, 20)      # Detection slope on wind
  mean.psi ~ dunif(0, 1)       # Occupancy intercept on prob. scale
  beta0 <- logit(mean.psi)     # Occupancy intercept
  beta1 ~ dunif(-20, 20)       # Occupancy slope on vegHt
  
  # Likelihood
  for (i in 1:M) {
    # True state model for the partially observed true state
    z[i] ~ dbern(psi[i])      # True occupancy z at site i
    logit(psi[i]) <- beta0 + beta1 * vegHt[i]
    for (j in 1:J) {
      # Observation model for the actual observations
      y[i,j] ~ dbern(p.eff[i,j])    # Detection-nondetection at i and j
      p.eff[i,j] <- z[i] * p[i,j]   # 'straw man' for WinBUGS
      logit(p[i,j]) <- alpha0 + alpha1 * wind[i,j]
    }
  }
  # Derived quantities are removed.
}
)
```

```{r}
occCode2 <- nimbleCode({
  # Priors
  mean.p ~ dunif(0, 1)         # Detection intercept on prob. scale
  alpha0 <- logit(mean.p)      # Detection intercept
  alpha1 ~ dunif(-20, 20)      # Detection slope on wind
  mean.psi ~ dunif(0, 1)       # Occupancy intercept on prob. scale
  beta0 <- logit(mean.psi)     # Occupancy intercept
  beta1 ~ dunif(-20, 20)       # Occupancy slope on vegHt
  
  # Likelihood
  for (i in 1:M) {
    # True state model for the partially observed true state
    logit(psi[i]) <- beta0 + beta1 * vegHt[i]
    y[i, 1:J] ~ dOcc_v(probOcc = psi[i], probDetect = p[i, 1:J], len = J)
    for (j in 1:J) {
      logit(p[i,j]) <- alpha0 + alpha1 * wind[i,j]
    }
  }
}
)
```

```{r}
dOcc_v <- nimbleFunction(
  run = function(x = double(1),
                 probOcc = double(0),
                 probDetect = double(1),
                 len = integer(0, default = 0),
                 log = logical(0, default = 0)) {
    if (len != 0) 
      if (len != length(x))
        stop("Argument 'len' must match length of data, or be 0.")
    if (length(x) != length(probDetect))
      stop("Length of data does not match length of detection vector.")
    returnType(double(0))
    logProb_x_given_occupied <- sum(dbinom(x,
                                           prob = probDetect, 
                                           size = 1,
                                           log = TRUE))
    prob_x_given_unoccupied <- sum(x) == 0
    prob_x <- exp(logProb_x_given_occupied) * probOcc + 
      prob_x_given_unoccupied * (1 - probOcc)
    if (log)
      return(log(prob_x))
    return(prob_x)
  }
)
rOcc_v <- nimbleFunction(
  run = function(n = integer(),
                 probOcc = double(0),
                 probDetect = double(1),
                 len = integer(0, default = 0)) {
    if(len != 0) {
      if (len != length(probDetect)) {
        stop("If argument 'len' is given, it must match length of probDetect.")
      }
    }
    returnType(double(1))
    k <- length(probDetect)
    u <- runif(1, 0, 1)
    if(u > probOcc) return(numeric(0, length = k))
    return(rbinom(k, prob = probDetect, size = 1))
  }
)
```

```{r}
occCode3 <- nimbleCode({
  # Priors
  mean.p ~ dunif(0, 1)         # Detection intercept on prob. scale
  alpha0 <- logit(mean.p)      # Detection intercept
  alpha1 ~ dunif(-20, 20)      # Detection slope on wind
  mean.psi ~ dunif(0, 1)       # Occupancy intercept on prob. scale
  beta0 <- logit(mean.psi)     # Occupancy intercept
  beta1 ~ dunif(-20, 20)       # Occupancy slope on vegHt
  
  # Likelihood
  logit(p[1:M,1:J]) <- alpha0 + alpha1 * wind[1:M,1:J]
  for (i in 1:M) {
    # True state model for the partially observed true state
    z[i] ~ dbern(psi[i])      # True occupancy z at site i
    logit(psi[i]) <- beta0 + beta1 * vegHt[i]
    p.eff[i, 1:J] <- z[i] * p[i, 1:J]   # 'straw man' for WinBUGS
    for (j in 1:J) {
      # Observation model for the actual observations
      y[i,j] ~ dbern(p.eff[i,j])    # Detection-nondetection at i and j
    }
  }
  # Derived quantities are removed.
}
)
```

Running occupancy example via `compareMCMCs`
=====
This slide runs each case of the occupancy model via `compareMCMCs`.

`compareMCMCs` times the MCMC and calculates summary metrics from the results.

`compareMCMCs` can also run JAGS (support for WinBUGS/OpenBUGS and Stan is coming).

```{r eval=recalculate}
result_orig <- compareMCMCs(list(code = Section10p4_code,
                                 constants = occupancy_data,
                                 inits = occupancy_inits()),
                            MCMCs = c("nimble", "jags"),
                            MCMCcontrol = list(niter = 10000,
                                               burnin = 2000))
result_orig <- renameMCMC(result_orig, "nimble_orig", "nimble")

saveRDS(result_orig, file = "result_orig.RDS")

result_dOcc <- compareMCMCs(list(code = occCode2,
                                 constants = occupancy_data,
                                 inits = occupancy_inits()),
                            MCMCs = c("nimble"),
                            MCMCcontrol = list(niter = 10000,
                                               burnin = 2000))
result_dOcc <- renameMCMC(result_dOcc, "nimble_dOcc", "nimble")

result_vec <- compareMCMCs(list(code = occCode3,
                                constants = occupancy_data,
                                inits = occupancy_inits()),
                           MCMCs = c("nimble"),
                           MCMCcontrol = list(niter = 10000,
                                              burnin = 2000))
result_vec <- renameMCMC(result_vec, "nimble_vec", "nimble")

```

Occupancy MCMC comparison results
=====
```{r eval=recalculate}
make_MCMC_comparison_pages(c(result_orig, result_dOcc, result_vec), modelName = "Occupancy")
```

Results are [here](Occupancy.html)

We see that:

- Default nimble is more efficient that JAGS.
- The `dOcc` nimble version is faster than default nimble.
- The vectorized version is similar to default nimble.

Look more closely at mixing
=====
Samples are not sequentially independent.

```{r include = FALSE}
if(!recalculate)
  result_orig <- readRDS("result_orig.RDS")
```

Look at the entire trace plot for `mean.p`:
```{r}
i <- 1:nrow(result_orig$nimble_orig$samples)
plot(i, result_orig$nimble_orig$samples[i, "mean.p"], pch = ".", ylab = "mean.p")
```

Look a little closer:
```{r}
i <- 1001:2000
plot(i, result_orig$nimble_orig$samples[i, "mean.p"], pch = ".", ylab = "mean.p")
```

Look really close:
```{r}
i <- 1001:1200
plot(i, result_orig$nimble_orig$samples[i, "mean.p"], pch = ".", ylab = "mean.p")
```

We see both autocorrelation and Metropolis-Hastings
rejections, which have occurred when the state does not change.  (This
does not happen in JAGS, because it does not use Metropolis-Hastings.  You can change samplers in nimble easily.)


What is Effective Sample Size (ESS)
=====

- *Effective sample size (ESS)* is the equivalent number of
independent samples in an MCMC chain for one parameter.

# What does "equivalent number of independent samples" mean?

- If `p[i]` were drawn independently (m samples), we could say:

$\mbox{Var}[\overline{p[i]}] = \mbox{Var}[ \frac{1}{m} \sum_{i = 1}^m p[i] ]= \frac{\mbox{Var}[p[i]]}{m}$

- Instead, we have

$\mbox{Var}[\overline{p[i]}] = \frac{\mbox{Var}[p[i]]}{\mbox{ESS}}$

where ESS is the *Effective Sample Size*.

```{r, ess, eval = TRUE}
library(coda)
effectiveSize(result_orig$nimble_orig$samples)
```

We can see that the effective sample size is considerably smaller than the number of samples.

Measuring MCMC performance: MCMC efficiency
=====

We define *MCMC efficiency* as

$\frac{\mbox{ESS}}{\mbox{computation time}}$

- This is the number of effectively independent samples generated per time.
- ESS is different for every parameter.
- Computation time is the same for every parameter: the total time.
- We do not count setup steps like model building and compilation as
  part of computation time.  Even
  though these take time, we are more interested in the final MCMC
  performance.
- One needs a reasonable sample just to get a reasonable estimate of ESS.
- We generally do not thin when comparing methods because thinning always removes some information from a sample.  People might disagree on this choice.

A single number: Minimum MCMC efficiency
=====

- We want a single number to measure the performance of an MCMC.
- Often there are many fast-mixing parameters and one or a few
slow-mixing ones.
- We need all parameters to be mixed well to rely on results.
- Therefore our single measure of efficiency is:

**Net MCMC efficiency = Minimum MCMC efficiency over all parameters**

- Sometimes it is easier to look graphically at **pace = 1/efficiency**.

Why we don't care as much about mean MCMC efficiency
=====

- It is tempting to think mean (across parameters) of MCMC efficiency is a good measure of overall performance.
- If you rely on mean efficiency, you could end up like the statistician who drowned in a river with an average depth of three feet.
- If some parameters are mixing very well and others very poorly, you should not feel the results are acceptable.


